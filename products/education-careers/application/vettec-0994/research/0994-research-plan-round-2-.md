---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Form 22-0994: Research Plan - Round 2 
## VA Form 22-0994 ##
February 27 through March 20, 2019

#### Problem Statement 
As a Veteran, I want to apply for VET TEC education benefits as easily as possible.  I would like to bypass any questions that are unrelated to my specific situation.

#### Solution Hypothesis
By presenting VA Form 22-0994 in an easy to use interview format, displaying only those questions that relate to the Veteran's specific situation, pre-populating data, presenting contextual help and guiding the Veteran through the process of completing the forms, Vets.gov will simplify the process of applying for education benefits. The online VA Form 22-0994 form will improve the experience of applying for educational benefits. It will save the Veteran time, increase their satisfaction with the process, and make them more confident in their ability to apply for benefits independently.

#### Research Questions

The research is designed to answer the following questions:
 
* Do the enhancements implemented as a result of the first round of usability testing (2/4-2/6) effectively meet the needs of Veterans?
* Do users understand that the VET TEC application process involves completing both VA Form 22-0994 and VA Form 22-1990, if they haven't already?
* Do users understand that there is no need to complete a second VA Form 22-1990, if they have submitted one in the past? 


#### What knowledge will make us feel like the research process has been successful?
Learning about the issues Veterans encounter when completing the form will enable us write instructional copy to help them complete the form correctly. 


#### What kinds of users do we need to talk to answer our questions?

The following users have been identified:
* Veterans


#### What specific questions do we need to ask on our Usability Testing screener to get the right kinds of users to test the form?

In addition to the standard questions, which ensure a representative mix of participants, the screener should include the following questions and responses:
1.	Have you applied for VA educational benefits before? 
    * If yes, to Question 3
    * If no, to Question 2
2.	Are you interested in applying for VA educational benefits?
    * If yes, to Question 4
    * If no, end
3.	Do you have any VA educational benefits remaining? 
    * If yes, to Question 4
    * If no, end
4.	Are you interested in pursuing education in the high-tech industry? 
    * If high-tech, to Question 5
    * If other, determine applicability before Question 5
5.	What is your age range?  
    * If 22-45 years old, would you like to participate?
    * If other, end

#### What kind of user research do we want to conduct?

The following research methods will be used:

* Moderated Usability Testing of a high-fidelity prototype with:

  o	4 to 6 Veterans

* Moderated User Acceptance Testing in the staging or password-protected production environment with:

  o	4 to 6 Veterans

#### What testing and recording tools do we need to run the research sessions?

Remote Interviews will be recorded via WebEx
Usability test sessions will be recorded via WebEx
In-person notes will be taken by hand and/or on a computer. 

#### What artifacts do we need to support the research effort?

For the usability testing, the following artifacts will be developed:
* A high-fidelity, clickable InVision prototype
* Veteran Test Script

The InVision prototype will be ready by: 2/26/2019

The test scripts will be ready by: 2/26/2019

For user acceptance testing, the following artifacts will be developed: 
* Veteran Test Script

#### Who will fill the team roles?
#### Usability Testing
* Screener writers: Theresa McMurdo, Amy Knox
* Recruiter: Perigean
* Conversation guide writer: Theresa McMurdo, Amy Knox
* Prototype Designer: Cindy Cruz
* Moderator: Theresa McMurdo, Amy Knox
* Note-taker: Theresa McMurdo, Amy Knox and Cindy Cruz
* Observers: UX Team
* Research readout writer: Theresa McMurdo or Amy Knox

#### User Acceptance Testing
* Screener writer: Desiree Turner
* Recruiter: Perigean
* Conversation guide writer: Desiree Turner
* Moderator: Desiree Turner
* Note-taker: Theresa McMurdo, Amy Knox, Cindy Cruz, Jenny Walter
* Observers: UX Team, Jenny Walter


#### When do we want to conduct the testing?

Usability Testing of the Prototype 
* Usability Testing will be conducted 2/27/19-3/1/19
* Usability Testing timeslots on 
  * 2/27 and 3/1 will be scheduled from 9AM to 6PM (with at least 30 mins between sessions)
  * 2/28 will be scheduled from 9AM to 4PM (with at least 30 mins between sessions)
* Each session will last no longer than 45 minutes
* A debrief among team members will be held immediately after each session.
* The findings from usability testing will be synthesized once all sessions have occurred and a findings report will be made.

User Acceptance Testing
* User Acceptance Testing will be conducted 3/6/19-3/11/19
* User Acceptance Testing timeslots will be: Anytime between 10AM and 6PM with an hour between each session
* Each session will last no longer than 60 minutes
* A debrief among team members will be held immediately after each session.
* The findings from user acceptance testing will be synthesized once all sessions have occurred and a findings report will be made.

#### When do we need to start recruiting?

Usability Testing recruiting needs to be complete by: 02/26/2019

User Acceptance Testing recruiting needs to be completed by: 03/5/2019
