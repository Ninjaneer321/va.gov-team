---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Sprint Research Plan #
## VA Form 22-0994 ##
January 7, 2018 – January 18, 2019

#### Problem Statement 
As a Veteran, I want to apply for VET TEC education benefits as easily as possible.  I would like to bypass any questions that are unrelated to my specific situation.

#### Solution Hypothesis
By presenting VA Form 22-0994 in an easy to use interview format, displaying only those questions that relate to the Veteran's specific situation, pre-populating data, presenting contextual help and guiding the Veteran through the process of completing the forms, Vets.gov will simplify the process of applying for education benefits. The online VA Form 22-0994 form will improve the experience of applying for educational benefits. It will save the Veteran time, increase their satisfaction with the process, and make them more confident in their ability to apply for benefits independently.

#### Research Questions

The research is designed to answer the following questions:
 
* What challenges or common pitfalls do Veterans face when attempting to apply for educational benefits?
* What information does the VA need to receive from Veterans on VA Form 22-0994 to ensure that valid requests for educational benefits are approved?
* Where can we use conditional logic and branching to display only those questions that are relevant to the Veteran?
* What information and/or contextual help would be helpful on VA Form 22-0994 to ensure valid requests are approved?

#### What knowledge will make us feel like the research process has been successful?

Learning about the issues Veterans encounter when completing the form will help us write instructional copy to help them complete the form correctly. 

In addition, learning the intent behind each question will allow us to write the application in a way that encourages accurate and thorough completion of the form, including non-required questions.    

#### What kinds of users do we need to talk to answer our questions?

The following users have been identified:
* Veterans
* VA Business Stakeholder / IPT Team Members
* College Veterans Office Representatives
* VSOs 

#### What specific questions do we need to ask on our Usability Testing screener to get the right kinds of users to test the form?

In addition to the standard questions, which ensure a representative mix of participants, the screener should include the following questions and responses:
1.	Have you applied for VA educational benefits before? 
   * If yes, to Question 3
   * If no, to Question 2
2.	Are you interested in applying for VA educational benefits?
   * If yes, to Question 4
   * If no, end
3.	Do you have any VA educational benefits remaining? 
   * If yes, to Question 4
   * If no, end
4.	Are you interested in pursuing education in the high-tech industry? 
   * If high-tech, to Question 5
   * If other, determine applicability before Question 5
5.	What is your age range?  
   * If 22-45 years old, would you like to participate?
   * If other, end

#### What kind of user research do we want to conduct?

The following research methods will be used:
* Structured Interview with:
o	Veterans 
o	VA Business Stakeholders / IPT Team Members
o	College Veterans Office Representatives 
o	VSOs

* Moderated Usability Testing of a high-fidelity prototype with:
o	1-2 College Veterans Office Representatives
o	1-2 VSOs
o	4 to 6 Veterans

#### What testing and recording tools do we need to run the research sessions?

Remote Interviews will be recorded via WebEx
Usability test sessions will be recorded via WebEx
In-person notes will be taken by hand and/or on a computer. 

#### What artifacts do we need to support the research effort?

For the interviews, the following artifacts will be developed:
* Veteran Script
* Stakeholder / IPT Team Script/Questionnaire
* College Veterans Office Representatives Script/Questionnaire
* VSO Script/Questionnaire?

The interview scripts will be ready by: 1/16/2018

For the usability testing, the following artifacts will be developed:
* A high-fidelity, clickable InVision prototype
* Veteran Test Script
* Claims Examiner / VSO / CVOR Test Script

The InVision prototype will be ready by: 2/1/2019

The test scripts will be ready by: 2/8/2019

#### Who will fill the team roles?
* Screener writers: Theresa McMurdo, Amy Knox
* Recruiter: Perigean
* Conversation guide writer: Theresa McMurdo, Amy Knox
* Prototype Designer: Cindy Cruz
* Moderator: Theresa McMurdo, Amy Knox
* Note-taker: Theresa McMurdo, Amy Knox and Cindy Cruz
* Observers: UX Team
* Research readout writer: Theresa McMurdo or Amy Knox

#### When do we want to conduct the testing?
Interviews 
* Interviews will be conducted during the 2nd week of Sprint 12 (1/14/2019 – 1/18/2019) 
* Interview times will be based on participant availability.

Usability Testing of the Prototype 
* Usability Testing will be conducted during the 1st week of Booz Sprint 15 
(2/11/2019 – 2/15/2019) 
* Usability Testing timeslots will be: 9AM, 11AM, 1PM, 3PM, 5PM, 7PM
* Each session will last no longer than 45 minutes
* A debrief among team members will be held immediately after each session.
* The findings from usability testing will be synthesized once all sessions have occurred and a findings report will be made.

#### When do we need to start recruiting?

Interview Recruiting needs to be complete by: 1/11/2019

Usability Testing Recruiting needs to be complete by: 2/8/2019
