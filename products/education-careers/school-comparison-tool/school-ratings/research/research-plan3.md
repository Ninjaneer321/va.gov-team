---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Research Plan for School Ratings
As a designer I need to create a research plan to share with my team.	 	
## Goals	
1. What product & team are you doing this research for?	
- Booz Allen research for Education Services / OIT
2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

When Veterans are looking for schools within the Comparison tool, they want to know about the experiences of other Veterans to form a better understanding of what their personal experience at the school would be like. Ratings enable Veterans to quickly assess the suitability of a school (both pro and con), bolstering their confidence and level of comfort in deciding if a particular school is right for them.

3. Research questions: What question(s) do you hope to be able to answer after completing this research? 	

- What are users’ overall impressions of ratings?
   - What do users think of the ratings?
   - Do users think the ratings are useful?
   - Are there any aspects of the ratings design that users find confusing?
   - What’s users’ impression of how scores are calculated?
   - Do users think the “Not yet rated” scores affect the overall score?

- Do users understand the UI & supporting content?
   - Do users understand the “Not yet rated” indicators?
   - What do users believe “True to expectations” means?
   - What do users think of the “About Ratings” content?
   - Do users understand accordions can be expanded by clicking or tapping?

- How do users (want to) engage with ratings?
   - Are users interested in filtering search results by star ratings?
   - Are users interested in sorting search results by star ratings? 
   - Do users engage with the ratings category accordions? 

- How do ratings’ impact decision making?
   - How does the overall rating weigh into the user’s perception of the school?
   - How do the individual ratings weigh into the user’s perception of the school?

- What are users’ impressions of the new school card layout?



4. Hypothesis: What is your hypothesis for this research? 

We believe that Veterans will understand the rating categories and find the ratings useful, especially in determining the Veteran experience at a particular school.

## Method	
1.	What method of research are you planning? 	
  - Remote moderated usability testing	
  	
2.	Why this method? How does this methodology help you answer your research questions? 	

Researchers need to be able to see how users react and interact with school ratings.  We need to be able to ask about their impressions and expectations of those ratings to determine if the current design is meeting their needs.  We also need to identify any points of confusion and whether this feature will be valuable to Veterans.

3.	Where are you planning to do your research? 

 - Online using Zoom
 
4.	What will you be testing? 
 - Page and content
 
5.  If remote: What tool do you plan to use (Zoom, GoToMeeting, Webex)	
 - Zoom
 
## Participants and Recruitment	
1.	Participant criteria: What are you looking for in a participant?	  
	
- 8 participants total
   - Actively looking for a school to attend for themselves where they'll use their VA education benefits in the next 2-3 months or
   - In the last 6 months, looked for a school to attend for themselves where they'd use their VA education benefits
- 2 participants on mobile, 6 participants on desktop
- GI Bill beneficiaries
- Age range: 18-45
- Gender: Mix
- Geography: Geographically dispersed across US
- VA Benefit requirement:
    - 5 participants personally using or planning to use Chapter 33 Post-9/11 benefits
    - 3 participants personally using or planning to use education benefits other than Chapter 33 Post-9/11
- Technology: Access to a computer, preferably running Google Chrome browser
- Familiarity with technology: Any
- Login requirements: None

2.	What is your recruitment strategy? 	
- Recruitment will be performed by Perigean Technologies	

## When? 	
1.	Timeline: What dates do you plan to do research? 	  
*   Nov 3 - 6, 2020
2.	Prepare: When will the thing you are testing be ready? (Goes without saying, but should be a few days before testing will begin.) 
* By COB: Friday Oct 30, 2020
3. Length of Sessions: How long do you estimate each session will be? 
  - 45 minutes
4.	Availability: If applicable, when would you like sessions scheduled? 
- Tues, Nov 3:  9:30 - 10:15AM; 10:45 - 11:30AM; 1:15 - 2PM
- Wed, Nov 4: 1 - 1:45 PM; 2:15- 3PM;
- Fri, Nov 6: 9:30 - 10:15AM; 10:45 - 11:30 AM; 2:15 - 3PM;

5.	Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 
*  Monday, Nov 2nd

## Team Roles	
Please list the people who will be serving in each role.  	
- Moderator:	Amy Knox; 301.254.0907; knox_amy@bah.com
- Research guide writing and task development (usually but not always same as moderator):	Booz Allen UX team
- Participant recruiting & screening:	Perigean Technologies
- Project point of contact:	Amy Knox
- Participant(s) for pilot test: TBD
- Note-takers:	Jen Jones jones_jennifer2@bah.com; Emma Waters waters_emma@bah.com;
- Observers:	Brian Grubb brian.grubb@va.gov; Desiree Turner turner_desiree@bah.com; Joe Preisser joseph.preisser@va.gov; Joe Welton joseph.welton@va.gov; Will McCormack mccormack_will@bah.com; Lauren Anderson lauren.alexanderson@va.gov; Lacey Higley lacey.higley@va.gov; Matt Self matthew.self2@va.gov; Dan Shawkey shawkey_daniel@bah.com; Darla VanNieukerk darla.vannieukerk@va.gov; Tammy Hurley tammy.hurley1@va.gov; Darrell Neel neel_darrell@bah.com;Luke Tickner Lucas.Tickner@va.gov	

## Resources	
- Project Brief: 	
https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/product-outline.md

- Convo Guide: https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/research/discussion-guide3.md
- Synthesis	
https://app.mural.co/t/bahdigitalexperience6902/m/bahdigitalexperience6902/1603987127360/3d7a6715a61e808da4f6303cc24295c03ba7cb1d?sender=jonesjennifer26349 	
- Lessons Learned	
*Did you have any takeaways from the process of this research round that you want the team to remember for the future? Document them here.* 	
- Read-Out/Results	
  - https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/research/Ratings-Research-Readout-202011.pdf
