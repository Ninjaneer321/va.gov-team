---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Research Plan for School Ratings
As a designer I need to create a research plan to share with my team.	 	
## Goals	
1. What product & team are you doing this research for?	
  - Booz Allen research for Education Services / OIT
2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

When Veterans are looking for schools within the Comparison tool, they want to know about the experiences of other Veterans to form a better understanding of what their personal experience at the school would be like. Ratings enable Veterans to quickly assess the suitability of a school (both pro and con), bolstering their confidence and level of comfort in deciding if a particular school is right for them.
 
3. Research questions: What question(s) do you hope to be able to answer after completing this research? 	
  - What are Veterans' thoughts on consumer ratings generally? How do they factor into their decision-making process?
  - What would users think of the trustworthiness of ratings displayed on the Comparison Tool?
  - Whose ratings would be most valuable to Veterans (e.g. authenticated users versus unauthenticated, Veterans versus other beneficiaries, rater's experience with school - only applied, attended, graduated)?
  - What information would Veterans like to know from military-connected students about the school? Whatâ€™s important to them in choosing a school? What type of information would sway their opinion of the school (for good or bad)?
  - What level of trust would users have of ratings displayed on the Comparison Tool?
  - What do Veterans expect ratings to look like?
  - What value do Veterans see in quantitative ratings?
  - Where would the display of ratings be most valuable to users within the Comparison Tool (on profiles, on search results cards)?
4. Hypothesis: What is your hypothesis for this research? 
 - We believe that ratings will matter to GI Bill education beneficiaries and will influence their decision on where they use their GI Bill benefits. We believe that Veterans will want to know about the experience of other beneficiaries at a particular school to assess if that school will be a good fit for them..
## Method	
1.	What method of research are you planning? 	
  - Remote directed interviews	
  	
2.	Why this method? How does this methodology help you answer your research questions?
  - Since this work is still in discovery phase, the researchers need to understand what factors influence a Veteran's decision to attend a school, particularly in relation to the experiences of their fellow Veterans.  Interviews allow the researchers to determine the needs and wants of Veterans while leaving the design of the ratings open-ended.
3.	Where are you planning to do your research? 
   - Online using Zoom
4.	What will you be testing? 
   - We will be interviewing Veterans to obtain their thoughts and feelings on ratings.  We will not be testing or assessing any product or design at this time.
5.  If remote: What tool do you plan to use (Zoom, GoToMeeting, Webex)	
 - Zoom
## Participants and Recruitment	
1.	Participant criteria: What are you looking for in a participant?	
(Mention: Number of people, ages, accessibility preferences, geographical diversity, login requirements, VA benefit requirements, familiarity with technology, etc. Keep in mind, the more requirements, the more difficult the recruit, so give ample time to ensure the right participant mix.)	
 - 9 participants
 - GI Bill beneficiaries using a variety of education benefits
    - No more than 4 participants using any particular type of benefit (e.g. Post 9/11, Montgomery, Voc Rehab, etc.)
    - 4 - 5 GI Bill beneficiaries who will start using their GI Bill education benefits in the next 3 months 
    - 4 - 5 GI Bill beneficiaries who started using their GI Bill education benefits in the past 6 months

Age Range: 24-54

Gender: Mix

Geography: Geographically dispersed across US

VA Benefit requirement: Any education benefits

Technology: Access to a computer, preferably running Google Chrome browser

Familiarity with technology: Any

Login requirements: None

2.	What is your recruitment strategy? 	
 - Recruitment will be performed by Perigean Technologies	
## When? 	
1.	Timeline: What dates do you plan to do research? 	
 - June 23 - 25, 2020	
2.	Prepare: When will the thing you are testing be ready? 
 - By COB June 19, 2020
3. Length of Sessions: How long do you estimate each session will be? 
 - 45 minutes
4.	Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. Please request enough dates and time slots (e.g. Monday 9-1, 3-6; Tuesday 9-6, etc.). Be as flexible as possible, cognizant that many Veterans are only available before and after working times, and live across the U.S.	
 - Tuesday, June 23:  8:30 - 9:30 AM; 11 AM - 12 PM;12:30 - 1:30 PM; 3 - 4 PM;
 - Wednesday, June 24: 8:30 - 9:30 AM; 10 - 11 AM; 12:30 - 1:30 PM; 3 - 4 PM;
 - Thursday, June 25: 9:30 - 10:30 AM; 11 AM - 12 PM; 12:30 - 1:30 PM;
 
5.	Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 
 - Monday, June 22nd
## Team Roles	
Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	
Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	
- Moderator:	Amy Knox; 301.254.0907; knox_amy@bah.com
- Research guide writing and task development (usually but not always same as moderator):	Booz Allen UX team
- Participant recruiting & screening:	Perigean Technologies
- Project point of contact:	Amy Knox
- Participant(s) for pilot test:	
- Note-takers:	Cindy Cruz cruz_cindy@bah.com; Jen Jones jones_jennifer2@bah.com
- Observers:	Brian Grubb brian.grubb@va.gov; Desiree Turner turner_desiree@bah.com; Joe Preisser joseph.preisser@va.gov; Joe Welton joseph.welton@va.gov; Will McCormack mccormack_will@bah.com; Lauren Anderson lauren.alexanderson@va.gov; Lacey Higley lacey.higley@va.gov; Matt Self matthew.self2@va.gov; Dan Shawkey shawkey_daniel@bah.com; Darla VanNieukerk darla.vannieukerk@va.gov; Tammy Hurley tammy.hurley1@va.gov; Darrell Neel neel_darrell@bah.com;	
## Resources	
- [Product Outline](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/product-outline.md) 
- [Discussion guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/research/discussion-guide.md)	
- Synthesis	
https://app.mural.co/t/bahdigitalexperience6902/m/bahdigitalexperience6902/1592854683402/d460598d3b5ebe141b777b52af0eee19477046a5?sender=jonesjennifer26349	
- Lessons Learned	
*Did you have any takeaways from the process of this research round that you want the team to remember for the future? Document them here.* 	
- Read-Out/Results	
  - https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/education-careers/school-comparison-tool/school-ratings/research/SchoolRatings-DiscoveryReadout-202007.pdf
