---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Research Plan for MHV on VA.gov, Medications, March 2025

## Background

Our project is part of the Digital Health Modernization strategy, which aims to create a centralized place for Veterans to access their health information. As part of this effort, My HealtheVet (MHV) will be moved to VA.gov. We initially built and tested a prototype of Medications in MHV on VA.gov. We conducted usability studies and collected feedback that informed iterations on the website. In this round of usability testing we will assess the new functionality of educational content and explore further pain points.

You can read more about our Digital Health Modernization strategy [here](https://github.com/department-of-veterans-affairs/va.gov-team/tree/master/products/health-care/digital-health-modernization/product).

## OCTO Objectives

This research supports the following OCTO objectives:

1. Veterans can manage their health services online
2. Veterans and their families can find a single, authoritative source of information
3. Logged-in users have a personalized experience, with relevant and time-saving features

# Veteran Journey

This research fits into these points of a Veteran's Journey:

- Starting up
- Taking care of myself
- Retiring
- Aging

## Research Goals

1. Understand if Veterans notice the in-product education (IPE) components.
2. Understand how Veterans interact with the IPE components.
3. Understand Veterans’ perception of the IPE components.
4. Identify any pain points Veterans may experience in using the IPE components to help them understand Medications.  

## Outcome

The results of the study will help us determine if our designs provide the best user experience for Veterans to understand changes to Medications and to identify any pain points. This will inform future design iterations.

## Research questions

1. Does the in-product education (IPE) component help Veterans accomplish their goals in Medications on VA.gov?
2. How do Veterans interact with the IPE components?
3. What are Veterans’ perceptions of the IPE components?

## Hypothesis

_Hypothesis 1: Most Veterans will notice the IPE components._

_Hypothesis 2: Most Veterans will ignore the component on first seeing it but will choose “Don’t show again” on subsequent sightings._

_Hypothesis 3: Most Veterans will find the IPE components helpful._

## Methodology

We will conduct moderated usability testing sessions in which we will ask users to navigate a prototype while we observe their behavior, and ask follow-up prompts as needed.

## Location

Data collection will be remote. We will use Zoom.

## Research materials

- \[Link to conversation guide\](url goes here)
- \[Link to prototype\](url goes here)

## Recruitment**

### Recruitment approach

We will recruit participants independently.

### Recruitment criteria

We will schedule a total of 4 usability sessions.

Please make sure that ALL participants are willing to complete the session **on the device they specified when recruited** and:

- During the session, are willing to share their screen
- Have a working microphone on their device

### Criteria for participants (4)

- 4 participants who are screen reader users.
  - 2 participants who are JAWS users
  - 2 participants who are VoiceOver/NVDA users

### Screener for participants

1. What device will you use to join the session?
    1. Desktop/Laptop
    2. Mobile phone – Android
    3. Mobile phone – iPhone
    4. Tablet – Android
    5. Tablet – iPad
2. What screen reader will you use in the session?
    1. JAWS
    2. NVDA
    3. VoiceOver

## Timeline

### Prepare

- Pilots: We will schedule our own, thank you.

### Research sessions

- Planned dates of research: **TBD**

### Length of sessions

- Session length: 1 hour
- Buffer time between sessions: 30 minutes

### Availability

- We will schedule on our own.

## Team Roles

Moderator: Melissa Stern

Research guide writing and task development: Melissa Stern, Anne Costello Kennedy

Participant recruiting & screening: Melissa Stern and Anne Costello Kennedy

Project point of contact: Melissa Stern

Accessibility specialist: Riley Orr

Participants for pilot test: TBD – we will do this ourselves, thank you.

Note-takers: TBD

Observers: Kaitlin Fink, Alexia Wunder, Anne Costello Kennedy
