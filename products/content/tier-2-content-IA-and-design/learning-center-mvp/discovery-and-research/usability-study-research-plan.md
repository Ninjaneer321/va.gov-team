---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Research Plan for Learning Center MVP

Liz Lantz, Public Websites, July 16, 2020

## Goals	

1. What product & team are you doing this research for?	

   This research is for the Learning Center MVP, Public Websites team.

2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

   When the new VA.gov was launched, Veteran-facing benefit information was brought into the VA.gov site experience first; there wasn't a clear delineation of what was directly 'getting/managing a benefit' content vs. 'benefit-adjacent' content. Anything that was Veteran-facing was brought over. As more and more Veteran-facing content got added to the hubs, we needed a tiered content framework to ensure that the benefit hubs don't become 'an everything' hub, making it harder to find top task Veteran-facing benefit content in the benefit hubs. Tier 1 content (content and tools for getting/managing a benefit) is nearly complete, and we are beginning to address migrating the tremendous amount of tier 2 benefit-adjacent content for beneficiaries, and people who work with beneficiaries. 

   The Learning Center MVP is designed to support the following goals:

   - Help Veterans find Tier 2 content in a way that doesn't dilute, distract, and clutter Veterans' benefit top task content and UX. 

   - Increase self-service for Veterans, and those who support them, when they have questions about benefits or need to troubleshoot VA account problems.

   - Reduce calls to the call center and the need for in-person visits to VA locations to answer questions about benefits or to troubleshoot VA account problems.

3. Research questions: What question(s) do you hope to be able to answer after completing this research? 

   - Is the information easy to find using this search-focused, tag-based navigation?
   - How easily are people able to navigate between learning center articles, and topics?
   - Are the template labels (ex: FAQs, Checklist, About, Step-by-step, etc.) useful?
   - What do people see as the difference between the learning center search and overall site search?
   - Do people get confused if they click on a content link or CTA button in the learning center and it takes them to a benefit hub page? And vice versa? 
   - Do people understand that information they don't find in the learning center might be in the benefit hub?
   - Where would the most useful place be to provide links to the Learning Center?

4. Hypothesis: What is your hypothesis for this research? 	

   - People will easily understand how to use the search functionality.
   - Template labels will help people determine which search result is most relevant to their search.
   - People will understand the difference between the Learning Center search and global site search.
   - People won't explicitly differentiate between the benefit hub and the Learning Center; they'll default to using overall site search if they can't find what they're looking for in either place.
   - Our proposed IA will be effective for Veterans and those who support Veterans.

## Method	

1. What method of research are you planning? 	

   We're planning on doing a remote, moderated usability study.  We'll ask participants to go through a clickable prototype.

2. Why this method? How does this methodology help you answer your research questions? 	

   Having participants complete tasks in a clickable prototype will help us understand how easily they're able to find the information they're looking for, and gain insight into how they would go about looking for information they can't find.  The presence of a moderator will allow us to ask follow-up questions and guide the participant through the tasks.

3. Where are you planning to do your research?

   We'll do our research remotely, using Zoom.	

4. What will you be testing? *(Design mocks, card sort, prototype, page, content, etc.)* 	

   We'll be testing a clickable prototype.

## Participants and Recruitment	

1.	We'd like to interview 8 Veterans
   - Participants must be able to participate via a laptop or desktop. Phones/ipads will not work. 
   - Participants must be able to log into VA.gov using an ID.me account, a My HealtheVet account, or a DS Logon account. Multiple accounts are fine. 
   - We request the participant pool be diverse in:
     - Gender (ideally 4 women, 4 men)
     - Ethnicity/Race (at least 4 non-Caucasian)
     - Age. Ideally, we will have 
       - 2 people from 18-24
       - 2 people from 25-34
       - 2 people from 35-54
       - 2 people who are 55 or older.
     - Education level (at least 2 falling somewhere between "some high school" and "some college" on their response to "Highest Level of Education" question on registration form)
     - Geography
   - To ensure inclusivity, we request at least one participant that has identified cognitive impairments and/or functional disabilities. Diagnoses that may align with this would be Traumatic Brain Injury (TBI), Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), Autism, and Vertigo. Other conditions may be autism, aphasia, dyslexia, dyscalculia, distractibility, memory loss, reading difficulties, low tolerance for cognitive overload, and intellectual/adaptive functioning challenges such as learning and problem-solving.

**2. What is your recruitment strategy?**

- For usability study:
  - We will leverage Perigan's recruitment capabilities
  - In order to get 8 participants, we'd like Perigean to recruit 16, with the expectation that there be a max of 4 no shows.
  - We'll ask to cancel any remaining sessions once we hit 8. 

## When? 	

1. Timeline: What dates do you plan to do research? 	
   August 3-5, 2020

2. Prepare: When will the thing you are testing be ready? 

   July 17, 2020

3. Length of Sessions: How long do you estimate each session will be? 

   45 minutes

4. Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. 

   Please allow 30 minutes between sessions

   - August 3: 10:30am - 1pm, 2pm - 7pm

   - August 4: 7am - 4pm

   - August 5: 8am - 4pm

5. Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 	

   - Kelson Adams, kadams@governmentcio.com
   - Preferred date/time: 7/23, between 3:30-5pm EST
   - Back up date/time: 7/24 between 3:30-7pm EST

## Team Roles	

Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	

- Moderator: Liz Lantz, 843-898-4463, liz.lantz@adhocteam.us

- Research guide writing and task development (usually but not always same as moderator): Liz Lantz

- Participant recruiting & screening: Perigean 

- Project point of contact: Liz Lantz

- Participant(s) for pilot test: Kelson Adams, kadams@governmentcio.com

- Note-takers: Jen Lee, TBD (will use VSA team members)

- Observers:	

  - Jen Lee (jennifer.lee27@va.gov)

  - Ryan Thurlwell (Ryan.Thurlwell@va.gov)

  - Danielle Thierry (danielle.thierry@va.gov)

  - Beth Potts (beth.potts@va.gov)

  - John Hashimoto (John.Hashimoto@va.gov)

  - Kelson Adams (kadams@governmentcio.com)

  - Oksana Cyrwus (oksana.cyrwus@agile6.com)

  - Kevin Walsh ([kevin.walsh@civicactions.com](mailto:kevin.walsh@civicactions.com))

  - Laura Walsh ([lwalsh@madpow.net](mailto:lwalsh@madpow.net))

  - Nick Sullivan (nick.sullivan@adhoc.team)

  - Randi Hecht ([rhecht@governmentcio.com](mailto:rhecht@governmentcio.com))

  - Mikki Northuis ([mikki@adhocteam.us](mailto:mikki@adhocteam.us))

  - Selina Cooper ([scooper@governmentcio.com](mailto:scooper@governmentcio.com))

  - Anne Hurley ([ahurley@governmentcio.com](mailto:ahurley@governmentcio.com))

  - Steve Wirt ([steve.wirt@civicactions.com](mailto:steve.wirt@civicactions.com))

  - Jeff Barnes (Jeffrey.Barnes4@va.gov)

  - Chris Johnston Christopher.Johnston2@va.gov)

  - Lauren Alexanderson (Lauren.Alexanderson@va.gov)

  - Meg Peters (Meg.Peters@va.gov)

  - Martha Wilkes (Martha.Wilkes@va.gov)

  - Dave Conlon (David.Conlon@va.gov)

    

## Resources	

- [Product Outline](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/tier-2-content-IA-and-design/learning-center-mvp/product-outline.md) 
- [Convo Guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/tier-2-content-IA-and-design/learning-center-mvp/discovery-and-research/conversation-guide.md)
- [Prototype to be tested](https://vsateams.invisionapp.com/share/YJXZTKC6CN4)
- [Findings Summary](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/tier-2-content-IA-and-design/learning-center-mvp/discovery-and-research/learning-center-mvp-findings-summary.md)
