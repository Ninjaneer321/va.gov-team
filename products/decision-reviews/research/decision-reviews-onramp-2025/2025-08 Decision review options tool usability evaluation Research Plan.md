## **2025-08 Decision review options tool usability evaluation**

Research Plan 

Team: Decision Reviews\
Written by: [Kyra Berman-Gestring](mailto:kyra.berman-gestring@agile6.com) & [Lauren Dawson](mailto:lauren.dawson@agile6.com)\
Last updated: Sep 2, 2025

Uploaded to github:  Sep 2, 2025


## **Background**

Following the enactment of the Veterans Appeals Improvement and Modernization Act (AMA) of 2017, Veterans and claimants were given the ability to request a decision review through one of three main pathways: Higher-Level Review (HLR), Supplemental Claim (SC), or Board Appeal (BA). Each path has distinct eligibility rules, evidence requirements, and timelines. The Board Appeal pathway also includes three subtypes—Direct Review, Evidence Submission, and Hearing—each with their own specific considerations.

Despite these options, navigating the AMA review process remains challenging for Veterans. Many struggle to identify the appropriate Decision review path for their situation, leading to frequent missteps, delays in claim resolution, and sometimes unfavorable outcomes. Confusion is often compounded by unclear distinctions between certain choices—such as knowing when to file a Supplemental Claim versus a Claim for Increase (CFI)—or by missing deadlines and not understanding what to do next.

To address these gaps and to assist Veterans in selecting the appropriate pathway, we are developing a new unauthenticated tool, the guide "Explore disability claim decision review options". This new tool introduces a guided, interactive experience on [VA.gov](http://va.gov), which aims to improve the Veteran journey by offering clear, context-sensitive guidance and reducing friction caused by uncertainty, incorrect submissions, and fragmented information sources. This tool will use a guided, “wizard-style” experience to help Veterans navigate the complex decision review landscape. By tailoring questions to each individual’s circumstances, the tool aims to guide the user to recommend appropriate review options for their circumstance, with clear reasoning as to why certain options may be a good fit, and others may not. 

Product Brief \[[Github](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/decision-reviews/Enhanced-DR-Onramp-Initiative%20Brief.md)]


## **OCTO-DE Priorities**

Objective 1: VA’s digital experiences are the easiest and most efficient way to access VA health care and benefits.

- Key Result 1: Improve satisfaction with our web and mobile products by 5 points.


## [**Veteran Journey**](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/design/va-product-journey-maps/Veteran%20Journey%20Map.pdf) 

This work fits into the:

- “Taking care of myself” stage of the [Veteran Journey](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/design/va-product-journey-maps/Veteran%20Journey%20Map.pdf), and within that stage, the “Managing primary care and chronic health issues” phase 

- “Putting down roots” stage, and within that stage, the “Engaging VA to access benefits and services” phase

- “Retiring” stage, and within that stage, the “Finding additional sources of incomes” phase


## **Research Goals**

1. **Usability of flow**: Evaluate the usability of the Decision Review Guide screen flow

2. **Clarity of content**: Evaluate participant comprehension of the questions and helpfulness of the explanatory content

3. **Effectiveness of guide:** Assess participant satisfaction with the guide and their confidence in selecting a decision review pathway


## **Outcome** 

This research will be an initial study of this new feature, and will inform how we proceed with implementation. With our learnings, we will iterate to make improvements to the tool or revise our strategy using what we learned to propose an alternative solution. If we progress forward with this design strategy, we will continue further testing with participants using assistive technologies to ensure compliance and effectiveness for these users. 


## **Research Questions** 

- **Goal 1, Usability of flow:** Evaluate the usability of the guide, "Explore disability claim decision review options" screen flow

  - Do participants understand what the outcomes of using the tool will be before they start?

  - Does the number of questions and amount of content in the guide feel manageable?

- **Goal 2, Clarity of content**: Evaluate participant comprehension of the questions and helpfulness of the explanatory content

  - What do participants learn while using the tool?

  - Are there questions or text that cause confusion or erroneous responses?

  - Where do participants hesitate, backtrack, or request clarification?

- **Goal 3, Effectiveness of summary screens:** Assess participant satisfaction with the summary screen and how this screen impacts their confidence in selecting a decision review pathway

  - What information do participants wish they knew even after getting results from the tool?

  - What do participants think they would do next / with the results?

  - How confident are participants in the results information?

  - Do participants understand what the available decision review options are and the reasons behind them? 


## **Hypotheses** 

| GOAL        | HYPOTHESIS    | HOW WE ARE MEASURING THIS IN OUR STUDY |
|:--------------|:-----------|:------------|
| 1 | Participants will understand that the output of the flow is a tailored summary of options based on their personal circumstance.    | - Feedback: At beginning of flow, what do participants expect to “get” at the end?       |
| 1 | Participants understand they can use this tool for both planning and action.    | - Feedback: How might you use this tool in the future? <br>- Feedback: Is this guide something you would use to plan next steps? To start the decision review process? Both?      |
| 1     | There may be some confusion around what types of claims (disability vs. non-disability) can leverage this guide.  | - Feedback: What questions or considerations do participants have? <br>- Feedback: Do participants express uncertainty about types of claims that the guide will help with? <br>- Task completion: Is there confusion or dropoff at the “type of claim” question in flow?       |
| 1      | Participants will be able to move through every question and arrive at the appropriate summary screen, without assistance.  | - Feedback: What is this experience like for Veterans? Are there points of tension, friction, or confusion? - Feedback: Are frustrations observed or shared? <br>- Task completion: How many participants arrive at the summary screen? <br>- Time on task: How long does it take for participants to progress from intro page to summary screen?       |
| 2      | The guide will support participants learning of the different decision review pathways, and the unique requirements of each.   | - Feedback: What decision review pathway did they consider before the guide? And after? If there is a change, why? <br>- Feedback: What do they have to say about the cards on the summary page? <br>- Both available options, and those in the “all option” sections <br>- Feedback: From the summary screen, Is the user able to state one requirement of each pathway?       |
| 2     | The questions and helper text will support users in confidently and correctly selecting an answer.  | * Feedback: What questions or considerations do participants have? <br>- Feedback: Did the helper text influence the user’s choice? <br>- Feedback: Do participants ask for help/support or clarification? <br>- Task completion: Are there common errors observed from misunderstanding questions? <br>- Feedback: On a scale of 1-5, how confident are you in selecting the choice that is right for you? Can ask on specific screens (like 2.IS.3 about CFI, 2.H.2B.1 about BA: Hearing, or 2.S about Supplemental Claim, which is very restrictive in options), or general at end? <br>- Feedback: Listen/look for confusion around “you’re requesting” language in the summary screen. Do participants understand that there is further action needed to submit a DR?      |
| 2      | Some VA terminology will be confusing to Veterans (ex. service-connected, contested claim, etc.)  | Feedback: What questions or considerations do participants have? <br>- Listen for…”what does this mean?” <br>- Look for…confusion, hesitation <br>- Feedback: Do participants ask the meaning of certain terms?        |
| 3      | Participants will understand why certain options are applicable to their situation, and why others are not.  | Feedback: What questions or considerations do participants have? <br>- Feedback: What decision review pathway did they consider before the guide? And after? <br>- Feedback: Can the user explain back/articulate why a pathway is/isn’t available?        |
| 3      | Most participants will use the summary screen as a resource to return to later.  | Feedback: What do they have to say about their next step(s)? <br>- First-click: Where do users click first on the summary screen? (Print? Copy/bookmark link? More info links? Apply links?) <br>- Feedback: Look for…Participants will not be ready to immediately apply for a pathway, but need time to consider, confer, etc.      |
| 3        | The tone and language of available decision review options and all other options on the summary screen feel supportive and nonjudgmental. | - Feedback: Maybe ask about tone rating? (1: judgemental/ discouraging, 2: somewhat judgemental, 3: neutral, 4: supportive, 5: very supportive/ encouraging) <br>- Feedback: Does the tone of the options available to you on the summary screen support your ability to move forward?        | 
| 3      | Participants will not need additional context beyond the reasons provided on the personalized summary screens.  | Feedback: What questions or considerations do participants have? - Feedback: What might the users change about the summary screens? <br>- Feedback: Listen for…”I still don’t understand why X option is not for me…” or “this doesn’t tell me…” or “this page is missing…”       |
| 3      | Participants will consider options from the “Your options” section of the summary screen and not from the “All options” section.  | First click: Where would they click on summary screen? <br>- Feedback: Which options would you consider from the summary screen? Why?       |


## **Methodology**

This research approach is for remote moderated usability testing of the decision review Guide, using a coded-prototype on staging.VA.gov. These sessions will include a semi-structured interview at the beginning to gauge participant’s prior understanding of the decision review process. The usability test will ask participants to use information about their personal scenario to guide them through the flow and observe task completion and thought process. The session will end with a follow-up interview to assess the impact of the flow on the participant experience and understanding of decision review options.  


## **Location**

We will run a moderated usability study remotely on Zoom. 


## **Research materials**

1. Conversation Guide \[[Github](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/decision-reviews/research/decision-reviews-onramp-2025/2025-08%20Explore%20decision%20reviews%20for%20your%20disability%20claim%20Conversation%20Guide.md)]

2. Mock-ups of what we will test in staging \[[Figma](https://www.figma.com/design/5vAWK3wpBkJgG7ngLXYmht/Onramping-Tool?node-id=122-8973&t=fQYJ9qkpWYLokAPc-1)]


## **Recruitment** 

We will work with Perigean to recruit Veterans for this research.

We request that Perigean:

- Share a link or screenshot of the recruitment survey for this study, so we can review it before it goes out to participants

- Call participants to:

  -  remind them about the session, one day in advance.

- Conducts a tech-check prior to the session, to get the Veteran set up on Zoom & go over screen sharing on Zoom required for the testing


### **Recruitment approach**

We will work with Perigean to recruit 9 Veterans for this research. 

We would like to request a kickoff call with Perigean. \[Wednesday September 17th, 2025 at 10:00am CST]

**Recruitment criteria**

- Veterans: \[9]

- Caregivers: \[0]

- Dependents: \[0]

- Total: \[9]

- Ideal completed sessions: \[6]

**Primary criteria:**

- 50% of participants who have a previous decision review (Would prefer this is specifically a disability compensation-related decision review, but not required)

- 50% of participants who have worked with a representative or attorney related to claims

- 25%-33% of participants who identify as having cognitive difficulty

- Participants from a mix of backgrounds including: service era, device type, and digital literacy.

**Secondary criteria:**

- We’d like a mix of genders, age, race/ethnicity, and education  

  - Gender

    - Attempt At least 3 Veterans who identify as a gender other than male 

  - Age

    - At least 4 55+ 

  - Race/ethnicity

    - Attempt at least 4 that do not identify as White/Caucasian 

  - Education 

    - Attempt at least 4 with no degree 

**Screener questions:**

1. Have you ever filed a claim for disability compensation with VA in the past?

- Yes \[Recruit all] 

- No \[Remove]

2. Have you ever filed a VA decision review—such as a Supplemental Claim, Higher-Level Review, or Board Appeal—to contest a benefits decision?

- Yes (Please select all that apply): \[Recruit 4-5]

  - Disability compensation related \[Desire at least 50% or more]

  - Non-disability related

- No \[Recruit 4-5]

3. If you answered Yes to the previous question, which pathway did you most recently pursue? \[Recruit for all]

- Supplemental Claim

- Higher-Level Review

- Board Appeal

- Don’t remember

4. Have you ever worked with an accredited representative, Veterans Service Organization (VSO), or attorney on any VA claim?

- Yes \[Recruit 4-5]

- No \[Recruit 4-5]

5. Which devices do you regularly use to access VA websites or online resources? (Select all that apply) \[Recruit all, a mix]

- Desktop computer

- Laptop

- Tablet

- Smartphone

6. Are you able to join the Zoom session from a smartphone or a desktop / laptop computer?

- Yes \[Recruit all]

- No \[Remove]

7. Do you find it difficult to remember or learn new things, focus on a task, or make decisions? We ask this question because we want to make sure that our tools work for people who live with challenges like these. 

- Yes \[Recruit 3]

- No \[Recruit 6]

**Timeline**

- Research Review (research plan, conversation guide) (9 days before testing begins):  _Sept 5_

- Midpoint Review: skipping per Shira Goodman/Christian

- Pilot Session:  _Sept 25th_

- Testing Begins: _Oct 2nd_

Note

Please submit artifacts for [Research Review](https://depo-platform-documentation.scrollhelp.site/collaboration-cycle/Research-review.1781891143.html) 8-9 days prior to the first planned research day for remote studies so Perigean can begin recruiting one week prior. Perigean requires 2+ weeks for in-person.

Optional Kick-off Call with Perigean

- Suggested dates and times: \[Enter dates and times  09/17 10:00 CST]

Prepare

_When will the thing you are testing be finalized? Ideally it's ready a week before testing begins and has also been through a_ [_Midpoint review_](https://depo-platform-documentation.scrollhelp.site/collaboration-cycle/Midpoint-review.1781039167.html)_._

A pilot session is required. Please indicate the date and name of a mock participant for a pilot session.

Note

Send pilot participant email in study Slack channel

- Pilot participant name: \[Enter name]

- Date and time of pilot session: \[Enter time]

Research sessions

- Planned dates of research: \[Enter dates 10/2-10/16]

Length of sessions

- Session length: (e.g. 30 minutes, < 1 hour, up to 2 hours, up to 4 hours) \[60 minutes]

- Buffer time between sessions: (30 minutes recommended to reset between sessions, debrief with team, if a participant arrives late, or a session goes slightly over time) \[30 minutes]

- Maximum Sessions per day: (We all have limits - how many sessions can you and your team conduct in one day considering the session length, the mental strain of conducting sessions, other work you still need to complete in a day, etc?) \[2 sessions]


### **Availability**

When would you like sessions scheduled? Please list exact dates and times in EASTERN Standard Time.

Note

We recommend providing availability outside of work hours, as many Veterans are only available before and after working times, and live across the U.S.

Tip

Please request enough dates and at _least double the amount of time slots for the number of requested participants_. (e.g. 3/17, Monday 9:00AM-1:00PM, 3:00PM-6:00PM EST; 3/18, Tuesday 9:00AM-6:00PM EST, etc.; _12 time slots for 6 participants_). This helps Perigean book participants when there are more time slots available, and when sessions need to be rescheduled or filled in with further recruitment.

Place time slots between hash marks when in edit mode.

- \[10/06, Monday, 10:00 AM-12:00 PM] EST

- \[10/06, Monday, 2:00 PM-5:00 PM] EST

- \[10/07, Tuesday, 2:00 PM-5:00 PM] EST

- \[10/08, Wednesday, 2:30 PM-5:00 PM] EST

- \[10/09, Thursday, 10:00 AM- 1:30PM] EST

- \[10/09, Thursday, 3:00 PM- 4:00PM] EST

- \[10/10, Friday, 10:00 AM -03:00 PM] EST


## **Team Roles** 

## **Moderator:** [**Kyra Berman-Gestring**](mailto:kyra.berman-gestring@agile6.com) **&** [**Lauren Dawson**](mailto:lauren.dawson@agile6.com)

- Research guide writing and task development (usually but not always same as moderator): [Kyra Berman-Gestring](mailto:kyra.berman-gestring@agile6.com) & [Lauren Dawson](mailto:lauren.dawson@agile6.com)

- Participant recruiting & screening: [Kyra Berman-Gestring](mailto:kyra.berman-gestring@agile6.com) & [Lauren Dawson](mailto:lauren.dawson@agile6.com)

- Project point of contact: [Kyra Berman-Gestring](mailto:kyra.berman-gestring@agile6.com)

- Accessibility specialist (for sessions where support for assistive technology may be needed): [Tracy Tran](mailto:tracy.tran@agile6.com)

- Note-takers: [Kyra Berman-Gestring](mailto:kyra.berman-gestring@agile6.com), [Lauren Dawson](mailto:lauren.dawson@agile6.com), <julie.strothman@va.gov>

- Observers: List the names of people observing the sessions. This includes VA stakeholders, engineering team members, design team members, and any other people who might find this research relevant to their work. Spread observers across sessions. There should be no more than 3 total attendees (moderator, notetaker(s), observer(s)) per session on the VA side.

  - <ccrumlish@kindsys.us>

  - [Pam Macalintal](mailto:pam.macalintal@agile6.com)

  - <gxu@kindsys.us>

  - <jsea@kindsys.us>

  - <rmays@kindsys.us>

  - <julie.strothman@va.gov>

  - <amy.lai2@va.gov>

  - <cindy.lackey@coa.solutions>

  - <cory.sohrakoff@va.gov>

  - & others TBD


## **Approvals**

- Reviewed by \[OCTO Product Owner, Team Lead] on \[08-14-2025]

- Reviewed by OCTO Research-Ops Lead on \[MM-DD-YYYY]
