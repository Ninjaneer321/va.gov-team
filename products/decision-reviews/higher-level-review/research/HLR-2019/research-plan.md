---
# Research Plan Metadata
title: "Research Plan for [Team, Product, Date]"
date: YYYY-MM-DD
last_updated: YYYY-MM-DD
team: "[Team Name]"
product: "[Product Name]"
product_area: "[e.g., authenticated/unauthenticated]"

# Background Context
background:
  problem_statement: "[What problem is your product trying to solve?]"
  product_location: "[Where is this situated on VA.gov?]"
  user_familiarity: "[New product or iteration?]"
  product_brief_url: "[URL]"

# Research Design
methodology: "[e.g., usability testing, semi-structured interviews, card sort]"
research_format: 
  location: remote # Options: remote, in-person, hybrid
  in_person_details:
    facility: "[Location name if applicable]"
    point_of_contact: "[Name if applicable]"
    equipment: "[Equipment details if applicable]"
  moderated: true # Options: true, false
  
# Research Goals & Questions
research_goals:
  - goal_1: "[First research goal]"
  - goal_2: "[Second research goal]"
  - goal_3: "[Third research goal]"

research_questions:
  - "[Research question 1]"
  - "[Research question 2]"
  - "[Research question 3]"
  - "[Research question 4]"
  - "[Research question 5]"

hypotheses:
  - "[Hypothesis 1]"
  - "[Hypothesis 2]"
  - "[Hypothesis 3]"

expected_outcomes: "[How will findings advance the product?]"

# Recruitment & Participants
recruitment:
  recruiting_partner: "Perigean"
  approach: "[e.g., lean maximum variation]"
  
  primary_criteria:
    - "[Must-have criterion 1]"
    - "[Must-have criterion 2]"
    - "[Must-have criterion 3]"
    
  secondary_criteria:
    - "[Nice-to-have criterion 1]"
    - "[Nice-to-have criterion 2]"
    
  screener_questions:
    - question: "[Screener question text]"
      qualifying_response: "[Expected answer]"
      
participants:
  veterans: 0
  caregivers: 0
  dependents: 0
  total_recruited: 0
  completed_sessions_goal: 0
  
# Timeline & Sessions
timeline:
  pilot_date: "YYYY-MM-DD"
  pilot_participant: "[Name]"
  research_dates: "YYYY-MM-DD to YYYY-MM-DD"
  research_review_submission: "YYYY-MM-DD"
  
session_details:
  duration_minutes: 60
  buffer_minutes: 30
  max_sessions_per_day: 0
  
# Strategic Alignment
octo_priorities:
  - objective: "Objective 1"
    key_results: 
      - "[Specific KR if applicable]"
  - objective: "Objective 2"
    key_results:
      - "[Specific KR if applicable]"
      
veteran_journey_phases:
  - "[e.g., Getting Out]"
  - "[e.g., Starting Up]"
    
# Research Repository Tracking
related_research:
  previous_studies: 
    - "[Link to related past research]"
    
tags:
  - "[product-area]"
  - "[methodology]"
  - "[participant-type]"
  - "[research-phase]"
---

# Research Plan for Higher Level Review (HLR) usability testing

Unicorns, Higher Level Review, December 2019

## Goals
To understand potential usability issues and/or friction points that exist in the current HLR designs.
To understand how users comprehend the language within the HLR process (i.e. legacy appeal, opt-out, etc)
To identify any confusing/ambiguous steps in the flow of the HLR submission process.


### Background
Testing on the HLR designs have been conducted already. However some items have changed based upon technical needs that affected the previously tested designs. Therefore we are testing the latest designs.


### Research questions
- Do any usability issues exist in the latest HLR designs?
	- Are the steps clearly defined or self-explanatory?
	- Does the user needs more information to move forward?
- Is there any confusing or ambiguous language that exists in the HLR content?
	- Specifically, does the user understand “legacy appeals”?
		- How does the user respond to and understand the “opt-out of legacy” screen?
- Are there any confusing steps in the flow of the HLR submission process?
	- Does the user organically move from step to step?
	- Are users missing any information in order to feel confident moving forward?
- Are there other questions or concerns the user has while completing the HLR process?

### Hypotheses
- There are languages and terms in the flow that may confuse veterans (i.e. legacy appeals, opt-out, etc).
- Opt-out page could potentially alarm users because it is a deliberate and forced action to proceed in submitting the HLR process. (Users need to feel 100% confident that they know all the consequences of this action before moving forward).

### Method
- We have previously conducted moderated usability testing sessions for the initial iteration of the designs and have gained feedback.
- We will be using remote, moderated usability studies because we need to talk to Veterans to understand what usability issues have been solved and which issues exist within the latest HLR designs. 
- We will use Zoom to conduct these sessions.  
- We will ask Veterans to navigate to an Invision link (provided in the Zoom chat) and share their screens with us via Zoom.


## Participants
- 10 Veterans
- Must have filed a disability claim
- Variation in: age, location, experience with VA claims, tech savviness. 
- Must be able to describe to the researcher what they are trying to accomplish, what they are experiencing and thinking as they move through the prototype. 

## Recruitment
We will work with Perigean for recruiting. 

## When? 
1.	Timeline for usability testing: January 15-22, 2020
2.	Prepare: We're using an Invision prototype
3.  Length of Sessions: 55 minutes
4.	Availability: 11 am - 5 pm ET
5.	Pilot: Jan 14, 2020

## Team Roles 
- Moderator: Christian V. 
- Conversation guide writing and task development: Kevin S. and Christian V.
- Participant recruiting & screening: Perigean
- Project point of contact: Christian V.
- Participant(s) for pilot test: Kevin. S.
- Note-takers: Kevin S., ...
- Observers: Yana R., Nick S., Robin G., Silvio L., Andrea S., Shawna H., Kelly L., Maria V., Luke M.

## Resources

- [Discussion Guide]() *TBD*
- [Notes]() *TBD*
- [Synthesis]() *TBD*
- [Read-Out/Results]() *TBD*
This research plan was approved by Andrea Schneider on Friday, Jan 3rd, 2020.
